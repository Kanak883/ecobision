<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EcoScan - Waste Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2"></script>
    <style>
        /* Previous CSS stays the same */
        .camera-container {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto;
        }
        #webcam, #overlay {
            position: absolute;
            left: 0;
            top: 0;
            border-radius: 10px;
        }
    </style>
</head>
<body>
    <div id="container">
        <h1>ðŸŒ± EcoScan</h1>
        <div class="camera-container">
            <video id="webcam" autoplay muted playsinline></video>
            <canvas id="overlay"></canvas>
        </div>
        <button id="scanButton">Start Scanning</button>
        <div id="results"></div>
    </div>

    <script>
        let net;
        let isScanning = false;
        const materialMap = { /* keep previous mapping */ };

        // Add canvas drawing functions
        function drawDetection(ctx, obj, material) {
            const colors = {
                plastic: '#FF4757',
                metal: '#3498db',
                paper: '#2ed573',
                unknown: '#95a5a6'
            };
            
            // Draw bounding box
            ctx.strokeStyle = colors[material] || '#95a5a6';
            ctx.lineWidth = 3;
            ctx.strokeRect(...obj.bbox);
            
            // Draw label background
            ctx.fillStyle = colors[material] || '#95a5a6';
            const text = `${obj.class} (${Math.round(obj.score * 100)}%) - ${material}`;
            const textWidth = ctx.measureText(text).width;
            ctx.fillRect(obj.bbox[0], obj.bbox[1] - 20, textWidth + 10, 20);
            
            // Draw text
            ctx.fillStyle = 'white';
            ctx.font = '14px Arial';
            ctx.fillText(text, obj.bbox[0] + 5, obj.bbox[1] - 5);
        }

        async function detectObjects() {
            const video = document.getElementById('webcam');
            const canvas = document.getElementById('overlay');
            const ctx = canvas.getContext('2d');
            
            if (!video || !net) return;

            // Set canvas size to match video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const objects = await net.detect(video);
            
            // Clear previous frame
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Draw new detections
            objects.forEach(obj => {
                const material = materialMap[obj.class] || 'unknown';
                drawDetection(ctx, obj, material);
            });

            if (isScanning) {
                requestAnimationFrame(detectObjects);
            }
        }

        // Previous setupWebcam and event listeners remain the same
        // Add this to your existing setupWebcam function:
        async function setupWebcam() {
            const video = document.getElementById('webcam');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.width = video.videoWidth;
                        video.height = video.videoHeight;
                        resolve(video);
                    };
                });
            } catch (err) {
                console.error("Camera error:", err);
                alert("Please enable camera access to use this feature");
                return null;
            }
        }

        // Keep the rest of your existing code
    </script>
</body>
</html>
